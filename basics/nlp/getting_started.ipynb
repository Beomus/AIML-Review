{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7e38e8-5da2-4427-8fab-5e343a88db51",
   "metadata": {},
   "source": [
    "# Common natural language processing tasks and techniques\n",
    "\n",
    "## Tokenization\n",
    "Probably the first thing most NLP algorithms have to do is to split the text into tokens, or words. While this sounds simple, having to account for punctuation and different languages' word and sentence delimiters can make it tricky. You might have to use various methods to determine demarcations.\n",
    "\n",
    "## Embeddings\n",
    "[Word embeddings](https://en.wikipedia.org/wiki/Word_embedding) are a way to convert your text data numerically. Embeddings are done in a way so that words with a similar meaning or words used together cluster together.\n",
    "\n",
    "## Parsing & Part-of-speech Tagging\n",
    "Every word that has been tokenized can be tagged as a part of speech - a noun, verb, or adjective. The sentence the quick red fox jumped over the lazy brown dog might be POS tagged as fox = noun, jumped = verb.\n",
    "Parsing is recognizing what words are related to each other in a sentence - for instance the quick red fox jumped is an adjective-noun-verb sequence that is separate from the lazy brown dog sequence.\n",
    "\n",
    "## Word and Phrase Frequencies\n",
    "A useful procedure when analyzing a large body of text is to build a dictionary of every word or phrase of interest and how often it appears. The phrase the quick red fox jumped over the lazy brown dog has a word frequency of 2 for the. Phrase frequencies can be case insensitive or case sensitive as required.\n",
    "\n",
    "## N-grams\n",
    "A text can be split into sequences of words of a set length, a single word (unigram), two words (bigrams), three words (trigrams) or any number of words (n-grams).\n",
    "\n",
    "For instance the quick red fox jumped over the lazy brown dog with a n-gram score of 2 produces the following n-grams:\n",
    "\n",
    "- the quick\n",
    "- quick red\n",
    "- red fox\n",
    "- fox jumped\n",
    "- jumped over\n",
    "- over the\n",
    "- the lazy\n",
    "- lazy brown\n",
    "- brown dog\n",
    "\n",
    "## Noun phrase Extraction\n",
    "In most sentences, there is a noun that is the subject, or object of the sentence. In English, it is often identifiable as having 'a' or 'an' or 'the' preceding it. Identifying the subject or object of a sentence by 'extracting the noun phrase' is a common task in NLP when attempting to understand the meaning of a sentence.\n",
    "\n",
    "✅ In the sentence \"I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun.\", can you identify the noun phrases?\n",
    "\n",
    "In the sentence the quick red fox jumped over the lazy brown dog there are 2 noun phrases: quick red fox and lazy brown dog.\n",
    "\n",
    "## Sentiment analysis\n",
    "A sentence or text can be analysed for sentiment, or how positive or negative it is. Sentiment is measured in polarity and objectivity/subjectivity. Polarity is measured from -1.0 to 1.0 (negative to positive) and 0.0 to 1.0 (most objective to most subjective).\n",
    "\n",
    "## Inflection\n",
    "Inflection enables you to take a word and get the singular or plural of the word.\n",
    "\n",
    "## Lemmatization\n",
    "A lemma is the root or headword for a set of words, for instance flew, flies, flying have a lemma of the verb fly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8b6c3-7f90-483f-ab04-40a66e7a8649",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Translation\n",
    "\n",
    "A naive translation program might translate words only, ignoring the sentence structure.\n",
    "\n",
    " Another approach is to ignore the meaning of the words, and instead use machine learning to detect patterns. This can work in translation if you have lots of text (a corpus) or texts (corpora) in both the origin and target languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21ee568-e812-4375-8735-432f6f4530d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est une vérité universellement reconnue, qu'un homme célibataire en possession d'une bonne fortune, doit avoir besoin d'une femme !\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(\n",
    "    \"It is a truth universally acknowledged, that \\\n",
    "    a single man in possession of a good fortune, must be in want of a wife!\"\n",
    ")\n",
    "\n",
    "print(blob.translate(to=\"fr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39e9a6-545c-4ecc-b637-31ef48416a09",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7b47e-e029-4813-9daa-b5f2bcf5b3e5",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Another area where machine learning can work very well is sentiment analysis. A non-ML approach to sentiment is to identify words and phrases which are 'positive' and 'negative'. Then, given a new piece of text, calculate the total value of the positive, negative and neutral words to identify the overall sentiment.\n",
    "\n",
    "This approach is easily tricked as you may have seen in the Marvin task - the sentence Great, that was a wonderful waste of time, I'm glad we are lost on this dark road is a sarcastic, negative sentiment sentence, but the simple algorithm detects 'great', 'wonderful', 'glad' as positive and 'waste', 'lost' and 'dark' as negative. The overall sentiment is swayed by these conflicting words.\n",
    "\n",
    "The ML approach would be to manually gather negative and positive bodies of text - tweets, or movie reviews, or anything where the human has given a score and a written opinion. Then NLP techniques can be applied to opinions and scores, so that patterns emerge (e.g., positive movie reviews tend to have the phrase 'Oscar worthy' more than negative movie reviews, or positive restaurant reviews say 'gourmet' much more than 'disgusting')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594afd15-378e-4ebc-8c8c-b3d531f3234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote 1 has a sentiment of Sentiment(polarity=0.20952380952380953, subjectivity=0.27142857142857146)\n",
      "Quote 2 has a sentiment of Sentiment(polarity=0.7, subjectivity=0.8)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "quote1 = \"\"\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\"\"\n",
    "\n",
    "quote2 = \"\"\"Darcy, as well as Elizabeth, really loved them; and they were both ever sensible of the warmest gratitude towards the persons who, by bringing her into Derbyshire, had been the means of uniting them.\"\"\"\n",
    "\n",
    "sentiment1 = TextBlob(quote1).sentiment\n",
    "sentiment2 = TextBlob(quote2).sentiment\n",
    "\n",
    "print(\"Quote 1 has a sentiment of \" + str(sentiment1))\n",
    "print(\"Quote 2 has a sentiment of \" + str(sentiment2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
