{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "# reshaping into a 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# change the label from single int to an array \n",
    "# in accordance to the label\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "\n",
    "## Starting with a really simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(28*28,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model_simple.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=SGD(lr=1e-3),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `softmax` activation function for a multilabel classification as well as the loss of `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1875 [..............................] - ETA: 11:10 - loss: 210.9041 - accuracy: 0.0938WARNING:tensorflow:From C:\\Users\\trung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1371: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 6.8642 - accuracy: 0.3457 - val_loss: 1.2121 - val_accuracy: 0.6470\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.1208 - accuracy: 0.6536 - val_loss: 0.8909 - val_accuracy: 0.7337\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8615 - accuracy: 0.7326 - val_loss: 0.7729 - val_accuracy: 0.7762\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7004 - accuracy: 0.7835 - val_loss: 0.6555 - val_accuracy: 0.8207\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.6082 - accuracy: 0.8200 - val_loss: 0.5644 - val_accuracy: 0.8450\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5166 - accuracy: 0.8500 - val_loss: 0.5614 - val_accuracy: 0.8414\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4767 - accuracy: 0.8637 - val_loss: 0.4735 - val_accuracy: 0.8685\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4223 - accuracy: 0.8812 - val_loss: 0.5012 - val_accuracy: 0.8521\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3950 - accuracy: 0.8879 - val_loss: 0.4009 - val_accuracy: 0.8871\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3699 - accuracy: 0.8939 - val_loss: 0.3623 - val_accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "training_history = model_simple.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(10, activation='relu', input_shape=(28*28,)),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 1.0353 - accuracy: 0.6460 - val_loss: 0.3701 - val_accuracy: 0.8783\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.3285 - accuracy: 0.8954 - val_loss: 0.2641 - val_accuracy: 0.9197\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2339 - accuracy: 0.9261 - val_loss: 0.2290 - val_accuracy: 0.9273\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2048 - accuracy: 0.9355 - val_loss: 0.2048 - val_accuracy: 0.9348\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1747 - accuracy: 0.9447 - val_loss: 0.2020 - val_accuracy: 0.9360\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1580 - accuracy: 0.9499 - val_loss: 0.1796 - val_accuracy: 0.9440\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1458 - accuracy: 0.9523 - val_loss: 0.1770 - val_accuracy: 0.9443\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1325 - accuracy: 0.9579 - val_loss: 0.1789 - val_accuracy: 0.9445\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1157 - accuracy: 0.9628 - val_loss: 0.1724 - val_accuracy: 0.9457\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1100 - accuracy: 0.9636 - val_loss: 0.1731 - val_accuracy: 0.9462\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',\n",
    "                   verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.0989 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: nan - accuracy: 0.0967 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: nan - accuracy: 0.1003 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0980\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(128, activation='relu', input_shape=(28*28,)),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "training_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard_callback, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.5387 - accuracy: 0.1614 - val_loss: 2.0655 - val_accuracy: 0.2096\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0891 - accuracy: 0.1998 - val_loss: 2.0388 - val_accuracy: 0.2102\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0764 - accuracy: 0.1983 - val_loss: 2.0330 - val_accuracy: 0.2091\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0610 - accuracy: 0.2024 - val_loss: 2.0245 - val_accuracy: 0.2096\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0446 - accuracy: 0.2067 - val_loss: 2.0142 - val_accuracy: 0.2113\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0386 - accuracy: 0.2057 - val_loss: 2.0117 - val_accuracy: 0.2102\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0319 - accuracy: 0.2046 - val_loss: 2.0078 - val_accuracy: 0.2114\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0286 - accuracy: 0.2024 - val_loss: 2.0035 - val_accuracy: 0.2120\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0251 - accuracy: 0.2051 - val_loss: 2.0027 - val_accuracy: 0.2125\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0176 - accuracy: 0.2056 - val_loss: 1.9959 - val_accuracy: 0.2131\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(10, activation='relu', input_shape=(28*28,)),\n",
    "        Dropout(0.2),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "training_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard_callback, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2632 - accuracy: 0.4120 - val_loss: 3.9834 - val_accuracy: 0.7826\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.8721 - accuracy: 0.8098 - val_loss: 3.5609 - val_accuracy: 0.8486\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.5035 - accuracy: 0.8502 - val_loss: 3.2763 - val_accuracy: 0.8683\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.2225 - accuracy: 0.8698 - val_loss: 3.0150 - val_accuracy: 0.8827\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.9605 - accuracy: 0.8866 - val_loss: 2.8097 - val_accuracy: 0.8912\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.7428 - accuracy: 0.8954 - val_loss: 2.5936 - val_accuracy: 0.9005\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.5414 - accuracy: 0.9022 - val_loss: 2.4222 - val_accuracy: 0.9036\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3583 - accuracy: 0.9089 - val_loss: 2.2477 - val_accuracy: 0.9125\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.2045 - accuracy: 0.9099 - val_loss: 2.0934 - val_accuracy: 0.9154\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0550 - accuracy: 0.9145 - val_loss: 1.9553 - val_accuracy: 0.9177\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(10, activation='relu', input_shape=(28*28,)),\n",
    "        Dense(128, activation='relu', kernel_regularizer='l2'),\n",
    "        Dense(256, activation='relu', kernel_regularizer='l2'),\n",
    "        Dense(128, activation='relu', kernel_regularizer='l2'),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "training_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensorboard_callback, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
